# -*- coding: utf-8 -*-
"""Glitch Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11SL2z264atIeWEvgyMQiFLpDWvp_d0s4
"""

!pip install --upgrade tensorflow matplotlib seaborn

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model

import matplotlib.pyplot as plt
import numpy as np
import os
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from PIL import Image

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

train_dir = '/content/drive/MyDrive/GRAVITY SPY DATASET/train/train/'
validation_dir = '/content/drive/MyDrive/GRAVITY SPY DATASET/validation/validation/'
test_dir = '/content/drive/MyDrive/GRAVITY SPY DATASET/test/test/'

img_dim = 250  # Input image size

# Automatically extract class names
classes_list = sorted(os.listdir(train_dir))

train_datagen = ImageDataGenerator(rescale=1. / 255)
val_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_dim, img_dim),
    batch_size=64,
    class_mode='categorical',
    shuffle=True,
    seed=123
)

validation_generator = val_datagen.flow_from_directory(
    validation_dir,
    target_size=(img_dim, img_dim),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    seed=123
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_dim, img_dim),
    batch_size=1,
    class_mode='categorical',
    shuffle=False
)

test_size = len(test_generator.filenames)

input_shape = (img_dim, img_dim, 3)

model = Sequential([
    Conv2D(32, (10, 10), activation='relu', input_shape=input_shape),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(32, (5, 5), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(img_dim, activation="relu"),
    Dropout(0.25),
    Dense(len(classes_list), activation="softmax")
])

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

history = model.fit(
    train_generator,
    steps_per_epoch=32,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=32,
    verbose=1
)

model_save_path = '/content/drive/MyDrive/Classifier/real_only_model.h5'
model.save(model_save_path)
print(f" Model saved to: {model_save_path}")

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

predictions = model.predict(test_generator, steps=test_size, verbose=1)
y_pred = np.argmax(predictions, axis=1)
y_true = test_generator.classes

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes_list, yticklabels=classes_list)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Overall accuracy
acc = accuracy_score(y_true, y_pred)
print(f" Overall Test Accuracy: {acc:.4f}")

# Create a labeled confusion matrix dataframe
cm_df = pd.DataFrame(cm, index=classes_list, columns=classes_list)

# Add signal/class names as a column (optional, if needed for export)
cm_df['signal'] = classes_list

# Plot correlation heatmap
import seaborn as sns

plt.figure(figsize=(12, 12))
corr = cm_df.drop(columns='signal').corr()

ax = sns.heatmap(
    corr,
    vmin=0, vmax=1, center=0.5,
    cmap=sns.diverging_palette(0, 200, n=200),
    square=True,
    linewidths=.5,
    cbar_kws={"shrink": 0.5}
)

ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
)
plt.title("Confusion Matrix Correlation Plot")
plt.tight_layout()
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

acc = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='macro')
recall = recall_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')

print("Evaluation Metrics Summary")
print(f" Accuracy       : {acc:.4f}")
print(f" Precision (avg): {precision:.4f}")
print(f" Recall (avg)   : {recall:.4f}")
print(f" F1 Score (avg) : {f1:.4f}")

from sklearn.metrics import roc_auc_score

# Binarize true labels and predictions
from sklearn.preprocessing import label_binarize
y_true_bin = label_binarize(y_true, classes=range(len(classes_list)))

# Already predicted probabilities: predictions
try:
    auc_score = roc_auc_score(y_true_bin, predictions, average='macro', multi_class='ovr')
    print(f" Macro-average AUC-ROC: {auc_score:.4f}")
except ValueError:
    print(" AUC-ROC could not be computed (check class coverage in test set).")

import numpy as np
from sklearn.metrics import confusion_matrix

def compute_confusion_entropy(y_true, y_pred, num_classes):
    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))
    cm = cm.astype(np.float64)
    N = cm.shape[0]
    total = cm.sum()
    cen = 0.0

    for i in range(N):
        row_sum = cm[i, :].sum()
        if row_sum == 0:
            continue
        for j in range(N):
            if i == j:
                continue
            pij = cm[i][j] / row_sum
            pji = cm[j][i] / cm[j].sum() if cm[j].sum() > 0 else 0
            if pij > 0 and pji > 0:
                cen += pij * np.log2((2 * pij) / (pij + pji))

    cen = cen / N
    return cen
cen_score = compute_confusion_entropy(y_true, y_pred, num_classes=len(classes_list))
print(f" Confusion Entropy (CEN): {cen_score:.4f}")

def compute_far(y_true, y_pred, class_names, negative_class="No_Glitch"):
    idx = class_names.index(negative_class)

    # False Positives = predicted as class X, but true was No_Glitch
    false_positives = sum((y_pred == idx) & (y_true != idx))
    total_predictions = len(y_true)

    far = false_positives / total_predictions
    return far
far_score = compute_far(y_true, y_pred, classes_list, negative_class="No_Glitch")
print(f" False Alarm Rate (FAR for 'No_Glitch'): {far_score:.4f}")

from sklearn.metrics import recall_score

def compute_detection_efficiency(y_true, y_pred, class_names):
    recalls = recall_score(y_true, y_pred, average=None)
    print(" Detection Efficiency (per class):")
    for cls, r in zip(class_names, recalls):
        print(f"   ðŸ”¹ {cls:20s}: {r:.4f}")
compute_detection_efficiency(y_true, y_pred, classes_list)

import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import os

# Load the trained model
model_path = '/content/drive/MyDrive/Classifier/real_only_model.h5'
model = load_model(model_path)

# Set the class list (from training folder)
train_dir = '/content/drive/MyDrive/GRAVITY SPY DATASET/train/train'
class_names = sorted(os.listdir(train_dir))

# Choose a test image (include class name in path)
test_image_path = '/content/drive/MyDrive/GRAVITY SPY DATASET/test/test/Blip/H1_5uen6yDWiF_spectrogram_1.0.png'

# Extract true label from folder name
true_label = os.path.basename(os.path.dirname(test_image_path))

# Load and preprocess the image
img_dim = 250
img = image.load_img(test_image_path, target_size=(img_dim, img_dim))
img_array = image.img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# Predict
pred = model.predict(img_array)
predicted_class = class_names[np.argmax(pred)]

# Print results
print(f" True Label     : {true_label}")
print(f" Predicted Label: {predicted_class}")

# Show image with predicted label
plt.imshow(img)
plt.title(f"Predicted: {predicted_class}")
plt.axis('off')
plt.show()