# -*- coding: utf-8 -*-
"""DCGAN EVAL & GEN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eqIWpyejZ2qZtUYPN_blAzxT4pcQaWJ
"""

!pip install torch torchvision matplotlib
!pip install pytorch-fid torch-fidelity
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import torch
import torch.nn as nn
from torchvision.utils import save_image
from torchvision import transforms
from collections import defaultdict
from torch_fidelity import calculate_metrics
from PIL import Image
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np
import shutil
from tqdm import tqdm
from torchvision.datasets import ImageFolder

device = torch.device("cpu")

# Configuration (must match training)
nz = 256
embedding_dim = 256
num_classes = 21
image_size = 128

class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, embedding_dim)
        self.init_proj = nn.Linear(nz + embedding_dim, 2048 * 4 * 4)
        self.model = nn.Sequential(
            nn.ConvTranspose2d(2048, 1024, 4, 2, 1), nn.BatchNorm2d(1024), nn.ReLU(True), nn.Dropout(0.35),
            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  nn.BatchNorm2d(512),  nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1),   nn.BatchNorm2d(256),  nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),   nn.BatchNorm2d(128),  nn.ReLU(True),
            nn.ConvTranspose2d(128, 3, 4, 2, 1),     nn.Tanh()
        )

    def forward(self, z, labels):
        label_embedding = self.label_emb(labels)
        x = torch.cat([z, label_embedding], dim=1)
        x = self.init_proj(x).view(-1, 2048, 4, 4)
        return self.model(x)

G_ema = Generator().to(device)
checkpoint_path = "/content/drive/MyDrive/GAN128_RGB_Tuned/final_generator_ema_ep250.pth"
G_ema.load_state_dict(torch.load(checkpoint_path, map_location=device))
G_ema.eval()

print(" Generator loaded successfully on CPU.")

output_root = "/content/drive/MyDrive/GAN_Final_Synthetic_1000"
os.makedirs(output_root, exist_ok=True)

class_labels = sorted(os.listdir("/content/drive/MyDrive/GRAVITY SPY DATASET/train/train"))
if "None_of_the_Above" in class_labels:
    class_labels.remove("None_of_the_Above")

print(f"Classes to generate: {class_labels}")

samples_per_class = 1000

with torch.no_grad():
    for class_idx, class_name in enumerate(class_labels):
        save_path = os.path.join(output_root, class_name)
        os.makedirs(save_path, exist_ok=True)

        for i in range(samples_per_class):
            z = torch.randn(1, nz, device=device)
            label = torch.tensor([class_idx], device=device)
            gen_img = G_ema(z, label)
            save_image(gen_img, os.path.join(save_path, f"{class_name}_gen_{i+1:03}.png"), normalize=True)

        print(f" Generated 1000 images for class: {class_name}")

root_dir = "/content/drive/MyDrive/GAN_Final_Synthetic_1000"
selected_classes = ["Blip", "Tomte", "Koi_Fish"]

sample_images = []
labels = []

for cls in selected_classes:
    class_path = os.path.join(root_dir, cls)
    if os.path.isdir(class_path):
        imgs = sorted([f for f in os.listdir(class_path) if f.endswith(".png")])
        if imgs:
            sample_images.append(os.path.join(class_path, imgs[0]))
            labels.append(cls)

cols = 3
rows = 1

plt.figure(figsize=(15, 4))

for idx, (img_path, label) in enumerate(zip(sample_images, labels)):
    img = Image.open(img_path)
    plt.subplot(rows, cols, idx + 1)
    plt.imshow(img)
    plt.title(label, fontsize=12)
    plt.axis("off")

plt.tight_layout()
plt.show()

real_root = "/content/drive/MyDrive/GRAVITY SPY DATASET/train/train"
gan_root = "/content/drive/MyDrive/GAN_Generated_Spectragram_Imgs"
target_root = "/content/drive/MyDrive/Classification_dataset_gravity_spy"
os.makedirs(target_root, exist_ok=True)

# Get class list (excluding None_of_the_Above)
all_classes = sorted([cls for cls in os.listdir(real_root) if cls != "None_of_the_Above"])

N_total = 1000

print(" Merging real + GAN images into Classification_dataset_gravity_spy...\n")

for cls in tqdm(all_classes):
    # Create class folder in target location
    target_dir = os.path.join(target_root, cls)
    os.makedirs(target_dir, exist_ok=True)

    # Get real images
    real_dir = os.path.join(real_root, cls)
    real_imgs = sorted([f for f in os.listdir(real_dir) if f.endswith((".png", ".jpg", ".jpeg"))])

    # Copy real images first
    for i, fname in enumerate(real_imgs[:N_total]):
        src = os.path.join(real_dir, fname)
        dst = os.path.join(target_dir, f"real_{i+1:04}.png")
        shutil.copyfile(src, dst)

    # Fill the rest with GAN images
    needed = N_total - len(real_imgs)
    if needed > 0:
        gan_dir = os.path.join(gan_root, cls)
        gan_imgs = sorted([f for f in os.listdir(gan_dir) if f.startswith("gan_") and f.endswith(".png")])
        for j, fname in enumerate(gan_imgs[:needed]):
            src = os.path.join(gan_dir, fname)
            dst = os.path.join(target_dir, f"gan_{j+1:04}.png")
            shutil.copyfile(src, dst)

    print(f" {cls}: {len(real_imgs[:N_total])} real + {min(needed, len(gan_imgs))} GAN â†’ total: {len(os.listdir(target_dir))} images.")

real_path = "/content/drive/MyDrive/GRAVITY SPY DATASET/train/train"
fake_path = "/content/drive/MyDrive/Classification_dataset_gravity_spy"

# Use same transform as training
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# Load small batches for visualization
real_dataset = ImageFolder(root=real_path, transform=transform)
fake_dataset = ImageFolder(root=fake_path, transform=transform)

# Reduce size for speed
real_loader = torch.utils.data.DataLoader(real_dataset, batch_size=200, shuffle=True)
fake_loader = torch.utils.data.DataLoader(fake_dataset, batch_size=200, shuffle=True)

# Extract one batch from each
real_images, _ = next(iter(real_loader))
fake_images, _ = next(iter(fake_loader))

# Flatten and reduce channel depth
real_flat = real_images.view(real_images.size(0), -1).numpy()
fake_flat = fake_images.view(fake_images.size(0), -1).numpy()

# Combine
X = np.vstack((real_flat, fake_flat))
y = np.array([0]*real_flat.shape[0] + [1]*fake_flat.shape[0])  # 0=real, 1=fake

# t-SNE
tsne = TSNE(n_components=2, random_state=42)
X_embedded = tsne.fit_transform(X)

# Plot
plt.figure(figsize=(8, 6))
plt.scatter(X_embedded[y==0, 0], X_embedded[y==0, 1], label="Real", alpha=0.6)
plt.scatter(X_embedded[y==1, 0], X_embedded[y==1, 1], label="Fake", alpha=0.6)
plt.title("t-SNE: Real vs GAN-Generated Glitches")
plt.legend()
plt.grid(True)
plt.show()

source_root = "/content/drive/MyDrive/Classification_dataset_gravity_spy"
resized_root = "/content/drive/MyDrive/Classification_dataset_gravity_spy_resized"

transform = transforms.Compose([
    transforms.Resize(128),
    transforms.CenterCrop(128)
])

os.makedirs(resized_root, exist_ok=True)

for cls in sorted(os.listdir(source_root)):
    class_path = os.path.join(source_root, cls)
    save_path = os.path.join(resized_root, cls)
    os.makedirs(save_path, exist_ok=True)

    for img_name in tqdm(os.listdir(class_path), desc=f"Resizing {cls}"):
        img_path = os.path.join(class_path, img_name)
        if img_name.endswith((".png", ".jpg", ".jpeg")):
            img = Image.open(img_path).convert("RGB")
            img = transform(img)
            img.save(os.path.join(save_path, img_name))

from torch_fidelity import calculate_metrics

metrics = calculate_metrics(
    input1="/content/drive/MyDrive/GRAVITY SPY DATASET/train/train",
    input2="/content/drive/MyDrive/Classification_dataset_gravity_spy_resized",
    cuda=False,
    fid=True,
    isc=False,
    kid=False,
    samples_find_deep=True
)

print(f" Torch-Fidelity FID Score: {metrics['frechet_inception_distance']:.2f}")