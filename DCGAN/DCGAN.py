# -*- coding: utf-8 -*-
"""DCGAN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RDmwks6IkdHB5JWEdoS5qietFukBwgmS
"""

!pip install torch torchvision matplotlib
!pip install --upgrade torch torchvision torchaudio
!pip install pytorch-fid scikit-learn seaborn
!pip install pytorch-fid torch-fidelity

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os, torch, copy
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, utils
from torch.nn.utils import spectral_norm
from torch.amp import autocast
from torch.cuda.amp import GradScaler
from torch.cuda.amp import GradScaler, autocast
import os
from torchvision.utils import save_image
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import pandas as pd
from collections import defaultdict
import os, torch
import seaborn as sns
from torchvision import datasets, transforms, models
from torchvision.utils import make_grid
from sklearn.manifold import TSNE

"""Configuration and Dataset Loading"""

image_size = 128
batch_size = 128
nz = 256
embedding_dim = 256
num_classes = 21
num_epochs = 200
lr_g, lr_d = 0.0001, 0.0004
betas = (0.0, 0.99)
ema_decay = 0.999
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True

dataset_path = '/content/drive/MyDrive/GRAVITY SPY DATASET'
print(os.listdir(dataset_path))

metadata_df = pd.read_csv('/content/drive/MyDrive/GRAVITY SPY DATASET/trainingset_v1d1_metadata.csv')
metadata_df.label.value_counts()

import matplotlib.pyplot as plt
import torchvision.utils as vutils

batch_size = 128
transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.CenterCrop(image_size),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

dataset = datasets.ImageFolder(root=data_path, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)
real_batch = next(iter(dataloader))
images, labels = real_batch

plt.figure(figsize=(16, 16))
grid = vutils.make_grid(images[:128], nrow=16, padding=2, normalize=True)
plt.imshow(grid.permute(1, 2, 0).cpu())
plt.title("Training Dataset Batch (128 Images)")
plt.axis("off")
plt.show()

train_classes = os.listdir('/content/drive/MyDrive/GRAVITY SPY DATASET' + "/train"+'/train')
print(train_classes)

test_classes = os.listdir('/content/drive/MyDrive/GRAVITY SPY DATASET' + "/test"+'/test')
print(test_classes)

validation_classes = os.listdir('/content/drive/MyDrive/GRAVITY SPY DATASET' + "/validation"+'/validation')
print(validation_classes)

data_path = '/content/drive/MyDrive/GRAVITY SPY DATASET/train/train'
checkpoint_dir = '/content/drive/MyDrive/GAN128_RGB_Tuned/Checkpoints'
sample_dir = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples'
gen_save_dir = '/content/drive/MyDrive/GAN_Generated_Images'
os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(sample_dir, exist_ok=True)
os.makedirs(gen_save_dir, exist_ok=True)

"""Filtered Dataset Loader"""

# Data transformation pipeline and Custom dataset class that excludes 'None_of_the_Above'
transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.CenterCrop(image_size),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])
class FilteredImageFolder(datasets.ImageFolder):
    def find_classes(self, directory):
        classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]
        classes.sort()
        if 'None_of_the_Above' in classes:
            classes.remove('None_of_the_Above')
        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        return classes, class_to_idx
dataset = FilteredImageFolder(root=data_path, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
print(f"Filtered Dataset: {len(dataset)} images across {len(dataset.classes)} classes.")

"""Generator & Discriminator (Conditional DCGAN)"""

# Generator with class conditioning and transposed convolutions
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, embedding_dim)
        self.init_proj = nn.Linear(nz + embedding_dim, 2048 * 4 * 4)

        self.model = nn.Sequential(
            nn.ConvTranspose2d(2048, 1024, 4, 2, 1), nn.BatchNorm2d(1024), nn.ReLU(True), nn.Dropout(0.3),
            nn.ConvTranspose2d(1024, 512, 4, 2, 1),  nn.BatchNorm2d(512),  nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1),   nn.BatchNorm2d(256),  nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),   nn.BatchNorm2d(128),  nn.ReLU(True),
            nn.ConvTranspose2d(128, 3, 4, 2, 1),     nn.Tanh()
        )

    def forward(self, z, labels):
        label_embedding = self.label_emb(labels)
        x = torch.cat([z, label_embedding], dim=1)
        x = self.init_proj(x).view(-1, 2048, 4, 4)
        return self.model(x)

# Discriminator with projection and spectral normalization
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(num_classes, 8192)

        self.conv = nn.Sequential(
            spectral_norm(nn.Conv2d(3, 64, 4, 2, 1)),   nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3),
            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3),
            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)),nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3),
            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)),nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3),
            spectral_norm(nn.Conv2d(512, 512, 4, 2, 1)),nn.LeakyReLU(0.2, inplace=True), nn.Dropout(0.3),
        )
        self.fc = spectral_norm(nn.Linear(512 * 4 * 4, 1))

    def forward(self, x, labels):
        out = self.conv(x).view(x.size(0), -1)
        logits = self.fc(out)
        proj = torch.sum(out * self.label_emb(labels), dim=1, keepdim=True)
        return logits + proj

"""Initialization, Training & EMA Updates"""

G = Generator().to(device)
D = Discriminator().to(device)
G_ema = copy.deepcopy(G).eval().to(device)

opt_G = optim.Adam(G.parameters(), lr=lr_g, betas=betas)
opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=betas)
criterion = nn.BCEWithLogitsLoss()
scaler = GradScaler()
loss_history = {'G': [], 'D': []}

def update_ema(model, ema_model, decay=0.999):
    with torch.no_grad():
        for k, ema_v in ema_model.state_dict().items():
            ema_v.copy_(decay * ema_v + (1. - decay) * model.state_dict()[k])

"""Save Samples and Visualize Epoch Progress"""

def save_samples(epoch, model=None, save_dir=None):
    if model is None:
        model = G_ema

    if save_dir is None:
        save_dir = sample_dir

    os.makedirs(save_dir, exist_ok=True)

    model.eval()
    with torch.no_grad():
        z = torch.randn(num_classes, nz, device=device)
        labels = torch.arange(num_classes, device=device)
        samples = model(z, labels)
        grid = utils.make_grid(samples, nrow=7, normalize=True, padding=2)
        out_path = os.path.join(save_dir, f"epoch_{epoch:03}.png")
        utils.save_image(grid, out_path)
        print(f" Saved image grid for epoch {epoch:03}: {out_path}")

def plot_sample_comparison(epoch_list=[0, 50, 100, 150, 175, 200, 250], samples_dir=sample_dir):
    images = []
    for epoch in epoch_list:
        path = os.path.join(samples_dir, f"epoch_{epoch:03}.png")
        if os.path.exists(path):
            images.append(Image.open(path))
        else:
            print(f" Missing {path}")
    if images:
        plt.figure(figsize=(16, 4 * len(images)))
        for i, img in enumerate(images):
            plt.subplot(len(images), 1, i+1)
            plt.imshow(img)
            plt.title(f"Epoch {epoch_list[i]}")
            plt.axis('off')
        plt.tight_layout()
        plt.show()

"""Training Loop"""

save_samples(epoch=0, model=G)

def train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history):
    print(f" Starting training from epoch {start_epoch} to {end_epoch}...")

    for epoch in range(start_epoch, end_epoch):
        g_losses, d_losses = [], []

        for real_imgs, labels in dataloader:
            real_imgs, labels = real_imgs.to(device), labels.to(device)
            b = real_imgs.size(0)
            valid = torch.empty(b, 1, device=device).uniform_(0.8, 1.0)
            fake = torch.zeros(b, 1, device=device)

            real_imgs_noisy = real_imgs + 0.05 * torch.randn_like(real_imgs)

            # Generator
            z = torch.randn(b, nz, device=device)
            fake_labels = torch.randint(0, num_classes, (b,), device=device)
            opt_G.zero_grad()

            with autocast():
                gen_imgs = G(z, fake_labels)
                gen_imgs_noisy = gen_imgs + 0.05 * torch.randn_like(gen_imgs)
                g_loss = criterion(D(gen_imgs_noisy, fake_labels), valid)

            scaler.scale(g_loss).backward()
            scaler.step(opt_G)
            scaler.update()
            g_losses.append(g_loss.item())
            update_ema(G, G_ema, ema_decay)

            # Discriminator
            opt_D.zero_grad()
            with autocast():
                real_loss = criterion(D(real_imgs_noisy, labels), valid)
                fake_loss = criterion(D(gen_imgs_noisy.detach(), fake_labels), fake)
                d_loss = (real_loss + fake_loss) / 2

            scaler.scale(d_loss).backward()
            scaler.step(opt_D)
            scaler.update()
            d_losses.append(d_loss.item())

        loss_history['G'].append(torch.tensor(g_losses).mean().item())
        loss_history['D'].append(torch.tensor(d_losses).mean().item())
        print(f"[Epoch {epoch+1}] G: {loss_history['G'][-1]:.4f} | D: {loss_history['D'][-1]:.4f}")

        # Save checkpoints
        if (epoch + 1) in [50, 100, 150, 175, 200, 250]:
            save_samples(epoch + 1)
            torch.save({
                'G': G.state_dict(),
                'G_ema': G_ema.state_dict(),
                'D': D.state_dict(),
                'opt_G': opt_G.state_dict(),
                'opt_D': opt_D.state_dict(),
                'loss': loss_history,
                'epoch': epoch
            }, f"{checkpoint_dir}/ckpt_epoch_{epoch+1}.pth")

    print(f" Finished training stage: {start_epoch}â€“{end_epoch}")

start_epoch = 0
end_epoch = 50
loss_history = {'G': [], 'D': []}

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples/epoch_050.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 50)")
plt.show()

# Load checkpoint at epoch 50
ckpt_50 = torch.load("/content/drive/MyDrive/GAN128_RGB_Tuned/Checkpoints/ckpt_epoch_50.pth")
G_ema.load_state_dict(ckpt_50['G_ema'])

# Save with updated formatting to same folder
save_samples(epoch=50, model=G_ema, save_dir="/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050")

ckpt = torch.load(f"{checkpoint_dir}/ckpt_epoch_50.pth")
G.load_state_dict(ckpt['G'])
G_ema.load_state_dict(ckpt['G_ema'])
D.load_state_dict(ckpt['D'])
opt_G.load_state_dict(ckpt['opt_G'])
opt_D.load_state_dict(ckpt['opt_D'])
loss_history = ckpt['loss']
start_epoch = ckpt['epoch'] + 1
end_epoch = 100

print(f" Resuming training from epoch {start_epoch} to {end_epoch}...")
# Fine-Tune: Lower Discriminator LR
for param_group in opt_D.param_groups:
    param_group['lr'] = 0.0001

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

"""Generate Balanced Dataset of 2000 Samples for each Class"""

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples/epoch_100.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 100)")
plt.show()

ckpt_100 = torch.load("/content/drive/MyDrive/GAN128_RGB_Tuned/Checkpoints/ckpt_epoch_100.pth")
G_ema.load_state_dict(ckpt_100['G_ema'])

save_samples(epoch=100, model=G_ema, save_dir="/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050")

ckpt = torch.load(f"{checkpoint_dir}/ckpt_epoch_100.pth")
G.load_state_dict(ckpt['G'])
G_ema.load_state_dict(ckpt['G_ema'])
D.load_state_dict(ckpt['D'])
opt_G.load_state_dict(ckpt['opt_G'])
opt_D.load_state_dict(ckpt['opt_D'])
loss_history = ckpt['loss']
start_epoch = ckpt['epoch'] + 1
end_epoch = 150

# Fine-Tune: Lower Discriminator LR
for param_group in opt_D.param_groups:
    param_group['lr'] = 0.00005

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_150.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 150)")
plt.show()

ckpt = torch.load(f"{checkpoint_dir}/ckpt_epoch_150.pth")

G = Generator().to(device)
G.load_state_dict(ckpt['G'])

# Manually increase dropout after loading
G.model[3].p = 0.35
print(f" Generator dropout updated to: {G.model[3].p}")

opt_G = optim.Adam(G.parameters(), lr=lr_g, betas=betas)
G_ema.load_state_dict(ckpt['G_ema'])
D.load_state_dict(ckpt['D'])
opt_D.load_state_dict(ckpt['opt_D'])
loss_history = ckpt['loss']
start_epoch = ckpt['epoch'] + 1
end_epoch = 175

for param_group in opt_D.param_groups:
    param_group['lr'] = 0.000025

print(f" Discriminator LR set to: {opt_D.param_groups[0]['lr']}")

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_175.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 175)")
plt.show()

ckpt = torch.load(f"{checkpoint_dir}/ckpt_epoch_175.pth")
G = Generator().to(device)
G.load_state_dict(ckpt['G'])
G.model[3].p = 0.35
print(f" Generator dropout set to: {G.model[3].p}")
opt_G = optim.Adam(G.parameters(), lr=lr_g, betas=betas)

G_ema.load_state_dict(ckpt['G_ema'])
D.load_state_dict(ckpt['D'])
opt_D.load_state_dict(ckpt['opt_D'])
loss_history = ckpt['loss']

for param_group in opt_D.param_groups:
    param_group['lr'] = 0.000025
print(f" Discriminator LR set to: {opt_D.param_groups[0]['lr']}")

start_epoch = ckpt['epoch'] + 1
end_epoch = 200

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_200.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 200)")
plt.show()

ckpt = torch.load(f"{checkpoint_dir}/ckpt_epoch_200.pth")
G = Generator().to(device)
G.load_state_dict(ckpt['G'])
print(f" Generator dropout remains: {G.model[3].p}")
opt_G = optim.Adam(G.parameters(), lr=lr_g, betas=betas)
G_ema.load_state_dict(ckpt['G_ema'])
D.load_state_dict(ckpt['D'])
opt_D.load_state_dict(ckpt['opt_D'])
loss_history = ckpt['loss']
print(f" Discriminator LR remains: {opt_D.param_groups[0]['lr']}")
start_epoch = ckpt['epoch'] + 1
end_epoch = 250

train_gan_stage(start_epoch, end_epoch, G, D, G_ema, opt_G, opt_D, scaler, dataloader, loss_history)

grid_path = '/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_250.png'
img = Image.open(grid_path)

plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.title("GAN-Generated Glitches (Epoch 250)")
plt.show()

import os
import matplotlib.pyplot as plt
from PIL import Image
epoch_paths = {
    0:   "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_000.png",
    50:  "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_050.png",
    100: "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_100.png",
    150: "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_150.png",
    175: "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_175.png",
    200: "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_200.png",
    250: "/content/drive/MyDrive/GAN128_RGB_Tuned/Samples_Epoch_050/epoch_250.png",
}

images = []
labels = []

for epoch, path in epoch_paths.items():
    if os.path.exists(path):
        images.append(Image.open(path))
        labels.append(f"Epoch {epoch}")
    else:
        print(f" Missing: {path}")

plt.figure(figsize=(12, 4 * len(images)))

for i, img in enumerate(images):
    plt.subplot(len(images), 1, i + 1)
    plt.imshow(img)
    plt.title(labels[i], fontsize=14)
    plt.axis("off")

plt.tight_layout()
plt.show()

torch.save(G_ema.state_dict(), "/content/drive/MyDrive/GAN128_RGB_Tuned/final_generator_ema_ep250.pth")